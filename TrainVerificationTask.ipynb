{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from Dataset import YTBDatasetVer,YTBDatasetCNN\n",
    "from Network import NANNet,CNNNet\n",
    "import numpy as np\n",
    "from util import evaluate\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='3' # 设置跑第几个GPU\n",
    "# 使用cuda运算\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC曲线绘制函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, figure_name=\"roc.png\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig = plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig.savefig(os.path.join(\"./\", figure_name), dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YTBDatasetVer(csv_file='../splits.txt', root_dir='../aligned_images_DB', img_size=224,num_frames=100)\n",
    "dataload = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=8, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化萌新（模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NANNet(cnn_path='./checkpoints/cnn_modelacc0.9982.pth').to(device)\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看可以更新的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  if param.requires_grad:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取存储好的NAN模型权值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"nan_model_fix_CNN.pth\"))\n",
    "model.load_state_dict(torch.load(\"./checkpoints/nan_model_acc0.9551.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.init_weights()\n",
    "acc_max = 0\n",
    "# optimizer =torch.optim.RMSprop(model.parameters(),lr=0.001, weight_decay=1e-5)              #last\n",
    "optimizer =torch.optim.RMSprop(model.parameters(),lr=1e-4, weight_decay=1e-6)              #last\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(),lr=0.05)\n",
    "# optimizer=torch.optim.Adagrad(model.parameters(), lr=0.0005, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    total_size = 0\n",
    "    bar = tqdm(dataload)\n",
    "    labels, distances = [], []\n",
    "    for i, (x1, x2, y) in enumerate(bar):\n",
    "        optimizer.zero_grad()\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        l2, loss = model.process(x1, x2, y)\n",
    "        total_size += x1.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # b=pred.item()\n",
    "        distances.append(l2.detach().data.cpu().numpy())\n",
    "        labels.append(y.cpu().numpy())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        bar.set_postfix(loss=f\"{total_loss/(i+1):0.4f}\",\n",
    "                        epoch=f\"{epoch+1}\")\n",
    "    labels = np.concatenate(labels)\n",
    "    distances = np.concatenate(distances)\n",
    "\n",
    "    tpr, fpr, accuracy, val, val_std, far = evaluate(distances, labels)\n",
    "    print('\\33[91mTrain set: Accuracy: {:.8f}\\n\\33[0m'.format(np.mean(accuracy)))\n",
    "    plot_roc(fpr, tpr, figure_name=\"roc_train_epoch_{}.png\".format(epoch))\n",
    "\n",
    "    acc = np.mean(accuracy)\n",
    "    torch.save(model.state_dict(), \"nan_model.pth\")\n",
    "    if acc_max < acc:\n",
    "        acc_max = max(acc, acc_max)\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/nan_model_acc{acc_max:0.4f}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YTBDatasetVer(csv_file='../splits.txt', root_dir='../aligned_images_DB', img_size=224,num_frames=100,train=False)\n",
    "dataload = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=1, num_workers=2)\n",
    "model=NANNet(cnn_path='./cnn_model6.pth').to(device)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/nan_model_acc0.9551.pth\"))\n",
    "model = model.eval()\n",
    "\n",
    "acc_max = 0\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    total_size = 0\n",
    "    bar = tqdm(dataload)\n",
    "    labels, distances = [], []\n",
    "    for i, (x1, x2, y) in enumerate(bar):\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        l2, loss = model.process(x1, x2, y)\n",
    "        total_size += x1.size(0)\n",
    "        distances.append(l2.detach().data.cpu().numpy())\n",
    "        labels.append(y.cpu().numpy())\n",
    "        total_loss += loss.item()\n",
    "        bar.set_postfix(loss=f\"{total_loss/(i+1):0.4f}\",\n",
    "                        epoch=f\"{epoch+1}\")\n",
    "    labels = np.concatenate(labels)\n",
    "    distances = np.concatenate(distances)\n",
    "\n",
    "    tpr, fpr, accuracy, val, val_std, far = evaluate(distances, labels)\n",
    "    print('\\33[91mTrain set: Accuracy: {:.8f}\\n\\33[0m'.format(np.mean(accuracy)))\n",
    "    plot_roc(fpr, tpr, figure_name=\"roc_train_epoch_{}.png\".format(epoch))\n",
    "\n",
    "    acc = np.mean(accuracy)\n",
    "    torch.save(model.state_dict(), \"nan_model.pth\")\n",
    "    if acc_max < acc:\n",
    "        acc_max = max(acc, acc_max)\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/nan_model_acc{acc_max:0.4f}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多GPU训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] ='2，3'\n",
    "model=nn.DataParallel(model,device_ids=['0','1']) \n",
    "# model.init_weights()\n",
    "acc_max = 0\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(),lr=0.05)\n",
    "# optimizer =torch.optim.RMSprop(model.parameters(),lr=0.001, weight_decay=1e-5)              #last\n",
    "optimizer =torch.optim.RMSprop(model.parameters(),lr=1e-4, weight_decay=1e-6)              #last\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(),lr=0.05)\n",
    "# optimizer=torch.optim.Adagrad(model.parameters(), lr=0.0005, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    total_size = 0\n",
    "    bar = tqdm(dataload)\n",
    "    labels, distances = [], []\n",
    "    for i, (x1, x2, y) in enumerate(bar):\n",
    "        optimizer.zero_grad()\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        l2, loss = model.process(x1, x2, y)\n",
    "        total_size += x1.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # b=pred.item()\n",
    "        distances.append(l2.detach().data.cpu().numpy())\n",
    "        labels.append(y.cpu().numpy())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        bar.set_postfix(loss=f\"{total_loss/(i+1):0.4f}\",\n",
    "                        epoch=f\"{epoch+1}\")\n",
    "    labels = np.concatenate(labels)\n",
    "    distances = np.concatenate(distances)\n",
    "\n",
    "    tpr, fpr, accuracy, val, val_std, far = evaluate(distances, labels)\n",
    "    print('\\33[91mTrain set: Accuracy: {:.8f}\\n\\33[0m'.format(np.mean(accuracy)))\n",
    "    plot_roc(fpr, tpr, figure_name=\"roc_train_epoch_{}.png\".format(epoch))\n",
    "\n",
    "    acc = np.mean(accuracy)\n",
    "    torch.save(model.state_dict(), \"nan_model.pth\")\n",
    "    if acc_max < acc:\n",
    "        acc_max = max(acc, acc_max)\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/nan_model_acc{acc_max:0.4f}.pth\")\n",
    "torch.save(model.module.state_dict(), path)\n",
    "\n",
    "### 测试人脸验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更换CNN模型进行的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 初始化\n",
    "\n",
    "import os\n",
    "from torchvision import transforms \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from Dataset import YTBDatasetVer,YTBDatasetCNN\n",
    "from Network import NANNet,CNNNet\n",
    "import numpy as np\n",
    "from util import evaluate\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='3' # 设置跑第几个GPU\n",
    "# 使用cuda运算\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "### ROC曲线绘制函数\n",
    "\n",
    "def plot_roc(fpr, tpr, figure_name=\"roc.png\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig = plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig.savefig(os.path.join(\"./\", figure_name), dpi=fig.dpi)\n",
    "\n",
    "### 初始化数据集\n",
    "\n",
    "dataset = YTBDatasetVer(csv_file='../splits.txt', root_dir='../aligned_images_DB', img_size=224,num_frames=100)\n",
    "dataload = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=4, num_workers=0)\n",
    "\n",
    "\n",
    "### 改变读取desnet的cnn模型\n",
    "import torchvision.models as models\n",
    "model=NANNet().to(device)\n",
    "model.CNN.cnn_model=models.densenet161(num_classes=128).to(device)\n",
    "model.CNN.load_state_dict(torch.load('./checkpoints/densenet_cnn_acc0.9983.pth'))\n",
    "for param in model.CNN.parameters():\n",
    "    param.requires_grad = False\n",
    "model = model.train()\n",
    "\n",
    "### 查看可以更新的参数\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  if param.requires_grad:\n",
    "    print(name)\n",
    "\n",
    "### 读取存储好的NAN模型权值\n",
    "\n",
    "model.load_state_dict(torch.load(\"./checkpoints/desnet_nan_acc0.6200.pth\"))\n",
    "\n",
    "# 训练\n",
    "\n",
    "# model.init_weights()\n",
    "acc_max = 0\n",
    "# optimizer =torch.optim.RMSprop(model.parameters(),lr=0.001, weight_decay=1e-5)              #last\n",
    "optimizer =torch.optim.RMSprop(model.parameters(),lr=1e-1, weight_decay=1e-6)              #last\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(),lr=0.05)\n",
    "# optimizer=torch.optim.Adagrad(model.parameters(), lr=0.0005, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    total_size = 0\n",
    "    bar = tqdm(dataload)\n",
    "    labels, distances = [], []\n",
    "    for i, (x1, x2, y) in enumerate(bar):\n",
    "        optimizer.zero_grad()\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        l2, loss = model.process(x1, x2, y)\n",
    "        total_size += x1.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # b=pred.item()\n",
    "        distances.append(l2.detach().data.cpu().numpy())\n",
    "        labels.append(y.cpu().numpy())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        bar.set_postfix(loss=f\"{total_loss/(i+1):0.4f}\",\n",
    "                        epoch=f\"{epoch+1}\")\n",
    "    labels = np.concatenate(labels)\n",
    "    distances = np.concatenate(distances)\n",
    "\n",
    "    tpr, fpr, accuracy, val, val_std, far = evaluate(distances, labels)\n",
    "    print('\\33[91mTrain set: Accuracy: {:.8f}\\n\\33[0m'.format(np.mean(accuracy)))\n",
    "    plot_roc(fpr, tpr, figure_name=\"roc_train_epoch_{}.png\".format(epoch))\n",
    "\n",
    "    acc = np.mean(accuracy)\n",
    "    torch.save(model.state_dict(), \"desnet_nan.pth\")\n",
    "    if acc_max < acc:\n",
    "        acc_max = max(acc, acc_max)\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/desnet_nan_acc{acc_max:0.4f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
